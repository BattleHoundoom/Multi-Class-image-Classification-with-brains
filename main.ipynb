{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "p5jyxMrqZNgORjzkVKUIWC",
     "type": "MD"
    }
   },
   "source": [
    "# Brain Splitter\n",
    "This project is made by the Syntax Error 404 team in order to recognise and classify the MRI scans of patients who are diagnosed with the Alzheimer's disease in order to pinpoint and understand how affected they are by the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "MxHBDMfcKw0YnrnB2euc0T",
     "type": "MD"
    }
   },
   "source": [
    "## Installation\n",
    "\n",
    "If these packages/libraries are not already installed in your system, only then shall you run this code block. Without these libraries, the project will not be able to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "1DzMeVZiMG6aF7CfvYeYw5",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow as tf\n",
    "!pip install numpy as np\n",
    "!pip install matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "g5ZEaFUq55PlZo7fQQSbaD",
     "type": "MD"
    }
   },
   "source": [
    "## Importing the modules\n",
    "We import the required modules and libraries that the project uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "u9zLX1m7j94LKrgDdvoGh2",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "qEpEzsc10Uqh6Qfc5YXXHT",
     "type": "MD"
    }
   },
   "source": [
    "## The Model\n",
    "\n",
    "In the following code block, we initialise the model by adding the desired convolutional and pooling layers in order to condense the image down and highlight the most important features for the AI.\n",
    "\n",
    "Each **convolutional** layer reduces the high-dimensionality of images without losing out on data, basically condensing an image down to its most important parts. \n",
    "Each **pooling** layer physically reduces the file size and dimensions of the image. When both of these layers work together, the image size is physically halved while the compressed image still retains its original complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "etsYo7vqwsHkjP79h2MqhI",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # There are four output neuron. This is for the four classes that our data comes from\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "etvACVLYsV3yVvcvS5hDBI",
     "type": "MD"
    }
   },
   "source": [
    "## Training the model\n",
    "We use the `ImageDataGenerator` in order to ensure that all images received are internally categorised into training and test data. Furthermore, any new images entered are condensed into the specified file size and hence have a standard aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "1c9YgkeaGXRhtphNAdGOYb",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              metrics=['accuracy'],\n",
    "               loss='categorical_crossentropy')\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# All images will be rescaled by 1/255\n",
    "train_datagen = ImageDataGenerator(rescale=1/255, validation_split = 0.3)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        './data/',  # This is the source directory for training images\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=128,\n",
    "        # Since we use categorical crossentropy, we have multiple labels\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "# Flow validation images in batches of 128\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        './data/',  # This is the source directory for validation images (gets split in 0.3 ratio with training data)\n",
    "        target_size=(300, 300),  # All images will be resized to 300x300\n",
    "        batch_size=128,\n",
    "        # Since we use categorical crossentropy, we have multiple labels\n",
    "        class_mode='categorical',\n",
    "        subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch= train_generator.samples // 128,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps = validation_generator.samples // 128,\n",
    "      epochs=12,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "ius1b70e3GsCQwm8IclW6Q",
     "type": "MD"
    }
   },
   "source": [
    "## Training the Model (Shortcut)\n",
    "\n",
    "In order to skip the training of the model, you can load it from memory by running the following code block. You can ignore the 2 above code blocks **if you have the model saved** (saves a lot of time). Don't run this block if you have already trained and optimized the model in this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "hmGHmUJ8mx9ODpP1fIsPQP",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('./my_model/my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "mYsoofRve3bgsTpBRCwXJW",
     "type": "MD"
    }
   },
   "source": [
    "## Plotting based on training\n",
    "The following two code blocks focus on generating plots to map out the accuracy and loss on the training set as well as the validation dataset. This shows the relationship between both quantities across both sets of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "QTI0ovX8xBKappTEOpODmc",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history['accuracy'])+1)\n",
    "plt.plot(epochs, history.history['accuracy'], '-o')\n",
    "plt.plot(epochs, history.history['val_accuracy'], '-o')\n",
    "plt.title('Validation accuracy vs training accuracy per epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "h8MnqWaw2tfIEsfL2fS5ro",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(history.history['accuracy'])+1)\n",
    "plt.plot(epochs, history.history['loss'], '-o')\n",
    "plt.plot(epochs, history.history['val_loss'], '-o')\n",
    "plt.title('Validation loss vs training loss per epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "A4yHmogLtR9CqBD56lFhAC",
     "type": "MD"
    }
   },
   "source": [
    "## Prediction and Classification\n",
    "\n",
    "The below code block runs the model on our set of test data. It categorises the MRI scans of the brains into 1 of 4 categories which are:\n",
    "- Non-demented\n",
    "- Very mildly-demented\n",
    "- Mildly-demented\n",
    "- Moderately-demented\n",
    "\n",
    "Once classified and categorised, the images used for the testing will be *moved into the respective folders* in our directory to remove even this slight trouble involving human labour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "HUQpYXDRU0ScxyhEhA8cgB",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"./data/test_data\"):\n",
    "    if '.jpg' in filename or '.png' in filename or '.jpeg' in filename:\n",
    "        path = \"./data/test_data/\" + filename\n",
    "        img = tf.keras.utils.load_img(path, target_size=(300, 300))\n",
    "        x = tf.keras.utils.img_to_array(img)\n",
    "        x /= 255\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        images = np.vstack([x])\n",
    "        classes = model.predict(images, batch_size=10)\n",
    "        if classes[0].tolist().index(max(classes[0])) == 0:\n",
    "            print(\"mild :\" + str(max(classes[0])*100))\n",
    "            os.rename(path, \"./data/test_data/mild/\"+filename)\n",
    "        elif classes[0].tolist().index(max(classes[0])) == 1:\n",
    "            print(\"moderate :\" + str(max(classes[0])*100))\n",
    "            os.rename(path, \"./data/test_data/moderate/\"+filename)\n",
    "        elif classes[0].tolist().index(max(classes[0])) == 2:\n",
    "            print(\"non :\" + str(max(classes[0])*100))\n",
    "            os.rename(path, \"./data/test_data/no/\"+filename)\n",
    "        else:\n",
    "            print(\"very mild :\" + str(max(classes[0])*100))\n",
    "            os.rename(path, \"./data/test_data/verymild/\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "s5bb6krGW3OQX8sXKXvVnC",
     "type": "MD"
    }
   },
   "source": [
    "## Resetting the Test Program\n",
    "\n",
    "The following block of code resets the test data images to their original uncategorized directories. This should be run before starting every program (but after importing the dependencies as it relies on os) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "vNxQHpJPnKnjJYKZJlggVH",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"./data/test_data/mild\"):\n",
    "    os.rename(\"./data/test_data/mild/\"+filename, \"./data/test_data/\"+filename)\n",
    "for filename in os.listdir(\"./data/test_data/moderate\"):\n",
    "    os.rename(\"./data/test_data/moderate/\"+filename, \"./data/test_data/\"+filename)\n",
    "for filename in os.listdir(\"./data/test_data/no\"):\n",
    "    os.rename(\"./data/test_data/no/\"+filename, \"./data/test_data/\"+filename)\n",
    "for filename in os.listdir(\"./data/test_data/verymild\"):\n",
    "    os.rename(\"./data/test_data/verymild/\"+filename, \"./data/test_data/\"+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "E7NNK14ou78LImIfwb6Akn",
     "type": "MD"
    }
   },
   "source": [
    "## Clean up\n",
    "This code block is the final one in the program and is run to stop the current session and free up memory resources if required. Do this at the very end of the project to avoid having to train the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "wJ6uYTCikVv7XbT2Dy39DN",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "import signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "datalore": {
   "base_environment": "default",
   "computation_mode": "REACTIVE",
   "package_manager": "pip",
   "packages": [],
   "version": 1
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
